# PIPELINE DEFINITION
# Name: esg-training-pipeline
# Description: Train and export ESG RandomForest model
# Inputs:
#    bucket: str [Default: 'datasets']
#    csv_key: str [Default: 'company_esg_financial_dataset.csv']
#    model_bucket: str [Default: 'models']
#    model_key: str [Default: 'esg/model_esg_overall.joblib']
components:
  comp-train-component:
    executorLabel: exec-train-component
    inputDefinitions:
      parameters:
        bucket:
          parameterType: STRING
        csv_key:
          parameterType: STRING
        model_bucket:
          parameterType: STRING
        model_key:
          parameterType: STRING
    outputDefinitions:
      parameters:
        Output:
          parameterType: STRING
deploymentSpec:
  executors:
    exec-train-component:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - train_component
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'pandas' 'scikit-learn'\
          \ 'joblib' 'boto3'  &&  python3 -m pip install --quiet --no-warn-script-location\
          \ 'kfp==2.14.3' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"\
          3.9\"' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef train_component(bucket: str, csv_key: str, model_bucket: str,\
          \ model_key: str) -> str:\n    import os\n    import boto3\n    import pandas\
          \ as pd\n    from sklearn import preprocessing\n    from sklearn.preprocessing\
          \ import LabelEncoder\n    from sklearn.model_selection import train_test_split\n\
          \    from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n\
          \    from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error,\
          \ root_mean_squared_error\n    from sklearn.model_selection import RandomizedSearchCV\n\
          \    import joblib\n\n    # MinIO client\n    s3 = boto3.client(\n     \
          \   \"s3\",\n        endpoint_url=\"http://minio-service.kubeflow:9000\"\
          ,\n        aws_access_key_id=\"minio\",\n        aws_secret_access_key=\"\
          minio123\"\n    )\n\n    # Download dataset\n    local_csv = \"/tmp/data.csv\"\
          \n    s3.download_file(bucket, csv_key, local_csv)\n    df = pd.read_csv(local_csv)\n\
          \n    # Train\n    model_dir = \"/tmp/model\"\n\n    def train_model_esg_overall(df:\
          \ pd.DataFrame, model_dir: str = \"./trained_models\") -> str:\n       \
          \ # Placeholder for model training logic\n        print(df.head())\n\n \
          \       df['GrowthRate'] = df['GrowthRate'].fillna(df['GrowthRate'].mean())\n\
          \n        le = preprocessing.LabelEncoder()\n        df['NewCompanyName']\
          \ = le.fit_transform(df.CompanyName)\n\n        col = ['Industry', 'Region',\
          \ 'Year', 'Revenue', 'ProfitMargin', 'MarketCap',\n        'GrowthRate',\
          \ 'CarbonEmissions', 'WaterUsage', 'EnergyConsumption']\n\n        df_X\
          \ = df[col]\n        le = LabelEncoder()\n        df_X['Industry'] = le.fit_transform(df_X['Industry'])\n\
          \        df_X['Region'] = le.fit_transform(df_X['Region'])\n\n        df_Y\
          \ = df['ESG_Overall']\n        x_train, x_test, y_train, y_test = train_test_split(\n\
          \            df_X, df_Y, test_size=0.22, random_state=42)\n\n        print(\"\
          Model training started.\")\n        # Random Forest Regression\n       \
          \ rf = RandomForestRegressor()\n        # Hyperparameter grid\n        param_dist\
          \ = {\n            'n_estimators': [100, 200, 500],\n            'max_depth':\
          \ [None, 10, 20, 30],\n            'min_samples_split': [2, 5, 10],\n  \
          \          'min_samples_leaf': [1, 2, 4],\n            'max_features': ['auto',\
          \ 'sqrt'],\n            'bootstrap': [True, False]\n        }\n\n      \
          \  random_search = RandomizedSearchCV(\n            estimator=rf,\n    \
          \        param_distributions=param_dist,\n            n_iter=50,\n     \
          \       cv=5,\n            verbose=2,\n            scoring='r2',\n     \
          \       random_state=42,\n            n_jobs=-1\n        )\n\n        random_search.fit(x_train,\
          \ y_train)\n        best_rf = random_search.best_estimator_\n\n        #\
          \ Evaluate\n        y_pred = best_rf.predict(x_test)\n        r2 = r2_score(y_test,\
          \ y_pred)\n        mse = mean_squared_error(y_test, y_pred)\n        rmse\
          \ = root_mean_squared_error(y_test, y_pred)\n        mae = mean_absolute_error(y_test,\
          \ y_pred)\n\n        print(\"Best Parameters:\", random_search.best_params_)\n\
          \        print(f\"R\xB2 Score: {r2:.2f}\")\n        print(f\"MSE: {mse:.2f}\"\
          )\n        print(f\"MAE: {mae:.2f}\")\n        print(f\"RMSE: {rmse:.2f}\"\
          )\n\n        final_rf = RandomForestRegressor(**random_search.best_params_,\
          \ random_state=42)\n        final_rf.fit(df_X, df_Y)\n\n        print(\"\
          Saving the trained model...\")\n        os.makedirs(model_dir, exist_ok=True)\n\
          \        model_path = os.path.join(model_dir, \"model_esg_overall.joblib\"\
          )\n        joblib.dump(final_rf, model_path)\n        print(f\"[INFO] Saved\
          \ model to {model_path}\")\n\n        print(\"Model training completed.\"\
          )\n        return model_path\n\n    model_path = train_model_esg_overall(df,\
          \ model_dir=model_dir)\n\n    # Upload model back\n    s3.upload_file(model_path,\
          \ model_bucket, model_key)\n    print(f\"[INFO] Model uploaded to s3://{model_bucket}/{model_key}\"\
          )\n\n    return f\"s3://{model_bucket}/{model_key}\"\n\n"
        image: python:3.10
pipelineInfo:
  description: Train and export ESG RandomForest model
  name: esg-training-pipeline
root:
  dag:
    tasks:
      train-component:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-train-component
        inputs:
          parameters:
            bucket:
              componentInputParameter: bucket
            csv_key:
              componentInputParameter: csv_key
            model_bucket:
              componentInputParameter: model_bucket
            model_key:
              componentInputParameter: model_key
        taskInfo:
          name: train-component
  inputDefinitions:
    parameters:
      bucket:
        defaultValue: datasets
        isOptional: true
        parameterType: STRING
      csv_key:
        defaultValue: company_esg_financial_dataset.csv
        isOptional: true
        parameterType: STRING
      model_bucket:
        defaultValue: models
        isOptional: true
        parameterType: STRING
      model_key:
        defaultValue: esg/model_esg_overall.joblib
        isOptional: true
        parameterType: STRING
schemaVersion: 2.1.0
sdkVersion: kfp-2.14.3
